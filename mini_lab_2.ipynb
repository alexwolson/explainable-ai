{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LIME with XGBoost\n",
    "\n",
    "In this notebook, we will again use the Titanic dataset, but this time we will use the LIME package to explain the predictions of an XGBoost model. "
   ],
   "id": "b022c61604bec9ac"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Install the necessary libraries\n",
    "\n",
    "# !pip install -q dalex xgboost lime"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import dalex as dx\n",
    "import xgboost\n",
    "import lime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "79aaa984c436e9bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load and Preprocess Data\n",
    "\n",
    "Annoyingly, both LIME and XGBoost are very particular about how we provide them with categorical entries. We will fall back on just using one-hot encoding, which is not as fancy but is assured to work."
   ],
   "id": "1dcfe204d4649fec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = dx.datasets.load_titanic()\n",
    "\n",
    "X = df.drop(columns='survived')\n",
    "X = pd.get_dummies(X, columns=['gender', 'class', 'embarked'], drop_first=True)\n",
    "y = df.survived"
   ],
   "id": "ccc6cf4d8045bb51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X.head()",
   "id": "626d981034699d6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "5fe8ff4fe528f2d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Train the Model\n",
    "\n",
    "As before, we will train an XGBoost model on the training data."
   ],
   "id": "6d702471b90745d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = xgboost.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ],
   "id": "89774c6e86950108",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Explain the Model with LIME & dalex\n",
    "\n",
    "dalex uses the original lime package to estimate LIME under a unified API.\n",
    "\n",
    "dalex aims to improve the user's convenience by providing a simplified API compared to the actual LIME package. We will create an `explainer` object just like before, but this time we will use the `predict_surrogate` method to explain the model's predictions.\n"
   ],
   "id": "891466329f208eac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "explainer = dx.Explainer(model, X_train, y_train, label='XGBoost')",
   "id": "1a13f3d08853c533",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Our model outputs a continuous value between zero and one, but what we actually want is a hard 0 or 1 prediction. As you might imagine the simplest way to do this is to use a cutoff of 0.5, but we can also use the mean value of the target variable. This can help to compensate for class imbalance, which we certainly have here.",
   "id": "4342fa95fefda22c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "explainer.model_performance(cutoff=y.mean())",
   "id": "a02a44bec028d061",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "observation = X.iloc[[0]]\n",
    "explainer.predict(observation)"
   ],
   "id": "342dd21b441cb69a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Just like in the first mini-lab, we need to specify how the model can get predictions from the data. This time, we will use the `predict_proba` method, which returns the probability of each class. We will also cast the output to a float, as LIME expects this.",
   "id": "2718d561027deee7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predict_fn = lambda x: model.predict_proba(x).astype(float)\n",
    "explanation = explainer.predict_surrogate(observation, predict_fn=predict_fn)"
   ],
   "id": "bd9e3c4a90501fe9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "explanation.result",
   "id": "493d73be8a2d69b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "explanation.plot()",
   "id": "aa391a7d59158d00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Be careful! LIME algorithm, like many other explanations, involves randomness. A different random seed will result in a different explanation. Take a look below and see if the differences seem significant to you.",
   "id": "37cdd6260025ee89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for seed in range(4):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    exp = explainer.predict_surrogate(observation, predict_fn=predict_fn)\n",
    "    exp.plot(return_figure=True)\n",
    "    plt.title(f'Seed of {seed}')"
   ],
   "id": "e3c5b28396929825",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Explain with LIME package\n",
    "\n",
    "We can also directly use the LIME package, which produces slightly different visualizations. Note that the underlying behaviour is the same, but the API is different."
   ],
   "id": "9fea141eb82a7cce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X_train.values,\n",
    "    feature_names=X_train.columns,\n",
    "    mode='classification',\n",
    ")"
   ],
   "id": "911f46ad9742a5ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lime_explanation = lime_explainer.explain_instance(\n",
    "    data_row=observation.iloc[0],\n",
    "    predict_fn=lambda d: model.predict_proba(d)\n",
    ")   "
   ],
   "id": "19b74e0ffba7a3dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lime_explanation.as_list()",
   "id": "4de3c4511a6e9bf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lime_explanation.as_pyplot_figure()",
   "id": "102864015932e6eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lime_explanation.show_in_notebook()",
   "id": "4af687a0432f2571",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2c8aff8ee1134cbd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
